{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b0d2458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea retelei neuronale noi: 65.35%\n",
      "   instance_id predicted_algorithm  real_algorithm  match\n",
      "0            1      Branch and Cut  Branch and Cut   True\n",
      "1            2      Branch and Cut  Branch and Cut   True\n",
      "2            3      Branch and Cut  Branch and Cut   True\n",
      "3            4      Branch and Cut  Branch and Cut   True\n",
      "4            5      Branch and Cut  Branch and Cut   True\n"
     ]
    }
   ],
   "source": [
    "# Old Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "conn = sqlite3.connect('../test_mTSP.sqlite3')\n",
    "test_instances = pd.read_sql_query(\"SELECT * FROM instances\", conn)\n",
    "test_algorithms = pd.read_sql_query(\"SELECT * FROM algorithms\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "test_features = test_instances[['nr_cities', 'nr_salesmen', 'average_distance', 'stddev_distance', 'density',\n",
    "                                'salesmen_ratio', 'bounding_box_area', 'aspect_ratio', 'spread',\n",
    "                                'cluster_compactness', 'mst_total_length', 'entropy_distance_matrix']]\n",
    "scaler = StandardScaler()\n",
    "test_features = scaler.fit_transform(test_features)\n",
    "\n",
    "x_test = torch.tensor(test_features, dtype=torch.float32)\n",
    "\n",
    "with open('labels_order.txt') as f:\n",
    "    label_order = [line.strip() for line in f]\n",
    "    \n",
    "# model\n",
    "input_size = x_test.shape[1]\n",
    "output_size = len(label_order)\n",
    "model = NeuralNetwork(input_size, output_size)\n",
    "model.load_state_dict(torch.load('models/best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "\n",
    "predicted_algorithms = [label_order[class_idx.item()] for class_idx in predicted_classes]\n",
    "test_instances['predicted_algorithm'] = predicted_algorithms\n",
    "\n",
    "# calculate composite score for each real algorithm\n",
    "test_algorithms = test_algorithms.merge(\n",
    "    test_instances[['instance_id', 'nr_cities']],\n",
    "    on='instance_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Normalize time_taken È™i distance_gap global \n",
    "conn = sqlite3.connect('../train_mTSP.sqlite3')\n",
    "train_algorithms = pd.read_sql_query(\"SELECT * FROM algorithms\", conn)\n",
    "conn.close()\n",
    "\n",
    "time_min = train_algorithms['time_taken'].min()\n",
    "time_max = train_algorithms['time_taken'].max()\n",
    "gap_min = train_algorithms['distance_gap'].min()\n",
    "gap_max = train_algorithms['distance_gap'].max()\n",
    "\n",
    "test_algorithms['time_taken_norm'] = (test_algorithms['time_taken'] - time_min) / (time_max - time_min + 1e-8)\n",
    "test_algorithms['distance_gap_norm'] = (test_algorithms['distance_gap'] - gap_min) / (gap_max - gap_min + 1e-8)\n",
    "\n",
    "# Penalize branch and cut on large instances\n",
    "penalty = (\n",
    "    (test_algorithms['strategy'].str.lower() == 'branch and cut') &\n",
    "    (test_algorithms['nr_cities'] > 40)\n",
    ").astype(float) * (0.1)\n",
    "\n",
    "\n",
    "test_algorithms['composite_score'] = test_algorithms['normalized_cost'] * 0.65 + \\\n",
    "                                     test_algorithms['time_taken_norm'] * 0.25 + \\\n",
    "                                     test_algorithms['distance_gap_norm'] * 0.1 + penalty \n",
    "\n",
    "best_real = test_algorithms.loc[test_algorithms.groupby('instance_id')['composite_score'].idxmin()]\n",
    "best_real = best_real[['instance_id', 'strategy']].rename(columns={'strategy': 'real_algorithm'})\n",
    "\n",
    "\n",
    "# compare predictions with real best algorithms\n",
    "comparison = test_instances[['instance_id', 'predicted_algorithm']].merge(best_real, on='instance_id')\n",
    "comparison['match'] = comparison['predicted_algorithm'] == comparison['real_algorithm']\n",
    "\n",
    "final_comparison = comparison[['instance_id', 'predicted_algorithm', 'real_algorithm', 'match']]\n",
    "final_comparison.to_csv('comparatie_pred_vs_real_version1.csv', index=False)\n",
    "\n",
    "accuracy = final_comparison['match'].mean()\n",
    "print(f\"Acuratetea retelei neuronale noi: {accuracy:.2%}\")\n",
    "print(final_comparison.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f93bfc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea retelei neuronale noi: 86.14%\n",
      "   instance_id predicted_algorithm  real_algorithm  match\n",
      "0            1      Branch and Cut  Branch and Cut   True\n",
      "1            2      Branch and Cut  Branch and Cut   True\n",
      "2            3      Branch and Cut  Branch and Cut   True\n",
      "3            4      Branch and Cut  Branch and Cut   True\n",
      "4            5      Branch and Cut  Branch and Cut   True\n"
     ]
    }
   ],
   "source": [
    "# New Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sqlite3\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, output_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Load test data\n",
    "conn = sqlite3.connect('../test_mTSP.sqlite3')\n",
    "test_instances = pd.read_sql_query(\"SELECT * FROM instances\", conn)\n",
    "test_algorithms = pd.read_sql_query(\"SELECT * FROM algorithms\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Extract test features\n",
    "test_features = test_instances[['nr_cities', 'nr_salesmen', 'average_distance', 'stddev_distance', 'density',\n",
    "                                'salesmen_ratio', 'bounding_box_area', 'aspect_ratio', 'spread',\n",
    "                                'cluster_compactness', 'mst_total_length', 'entropy_distance_matrix']]\n",
    "\n",
    "# Load scaler\n",
    "with open('scaler_version2.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "x_test = torch.tensor(test_features_scaled, dtype=torch.float32)\n",
    "\n",
    "# Load label order\n",
    "with open('labels_order-v2.txt') as f:\n",
    "    label_order = [line.strip() for line in f]\n",
    "\n",
    "# Load model\n",
    "input_size = x_test.shape[1]\n",
    "output_size = len(label_order)\n",
    "model = NeuralNetwork(input_size, output_size)\n",
    "model.load_state_dict(torch.load('models_version2/best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test)\n",
    "\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "    predicted_algorithms = [label_order[class_idx.item()] for class_idx in predicted_classes]\n",
    "\n",
    "test_instances['predicted_algorithm'] = predicted_algorithms\n",
    "\n",
    "test_algorithms = test_algorithms.merge(\n",
    "    test_instances[['instance_id', 'nr_cities']],\n",
    "    on='instance_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Load train stats for normalization\n",
    "conn = sqlite3.connect('../train_mTSP.sqlite3')\n",
    "train_algorithms = pd.read_sql_query(\"SELECT * FROM algorithms\", conn)\n",
    "conn.close()\n",
    "\n",
    "time_min = train_algorithms['time_taken'].min()\n",
    "time_max = train_algorithms['time_taken'].max()\n",
    "gap_min = train_algorithms['distance_gap'].min()\n",
    "gap_max = train_algorithms['distance_gap'].max()\n",
    "\n",
    "# Normalize\n",
    "test_algorithms['time_taken_norm'] = (test_algorithms['time_taken'] - time_min) / (time_max - time_min + 1e-8)\n",
    "test_algorithms['distance_gap_norm'] = (test_algorithms['distance_gap'] - gap_min) / (gap_max - gap_min + 1e-8)\n",
    "\n",
    "# Penalize branch and cut on large instances\n",
    "penalty = (\n",
    "    (test_algorithms['strategy'].str.lower() == 'branch and cut') &\n",
    "    (test_algorithms['nr_cities'] > 40)\n",
    ").astype(float) * (0.1)\n",
    "\n",
    "test_algorithms['composite_score'] = test_algorithms['normalized_cost'] * 0.65 + \\\n",
    "                                     test_algorithms['time_taken_norm'] * 0.25 + \\\n",
    "                                     test_algorithms['distance_gap_norm'] * 0.1 + penalty \n",
    "\n",
    "# Find best real algorithm per instance\n",
    "best_real = test_algorithms.loc[test_algorithms.groupby('instance_id')['composite_score'].idxmin()]\n",
    "best_real = best_real[['instance_id', 'strategy']].rename(columns={'strategy': 'real_algorithm'})\n",
    "\n",
    "# Compare predictions with real best\n",
    "comparison = test_instances[['instance_id', 'predicted_algorithm']].merge(best_real, on='instance_id')\n",
    "comparison['match'] = comparison['predicted_algorithm'] == comparison['real_algorithm']\n",
    "\n",
    "# Save results\n",
    "final_comparison = comparison[['instance_id', 'predicted_algorithm', 'real_algorithm', 'match']]\n",
    "final_comparison.to_csv('comparatie_pred_vs_real_version2.csv', index=False)\n",
    "\n",
    "accuracy = final_comparison['match'].mean()\n",
    "print(f\"Acuratetea retelei neuronale noi: {accuracy:.2%}\")\n",
    "print(final_comparison.head())  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
