{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b0d2458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea retelei neruonale vechi: 68.32%\n",
      "   instance_id predicted_algorithm real_best_algorithm  \\\n",
      "0            1      branch and cut      Branch and Cut   \n",
      "1            2      branch and cut      Branch and Cut   \n",
      "2            3      branch and cut      Branch and Cut   \n",
      "3            4      branch and cut      Branch and Cut   \n",
      "4            5      branch and cut      Branch and Cut   \n",
      "\n",
      "  predicted_algorithm_match  match  \n",
      "0            Branch and Cut   True  \n",
      "1            Branch and Cut   True  \n",
      "2            Branch and Cut   True  \n",
      "3            Branch and Cut   True  \n",
      "4            Branch and Cut   True  \n"
     ]
    }
   ],
   "source": [
    "# Old Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "conn = sqlite3.connect('../test_mTSP.sqlite3')\n",
    "test_instances = pd.read_sql_query(\"SELECT * FROM instances\", conn)\n",
    "test_algorithms = pd.read_sql_query(\"SELECT * FROM algorithms\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "test_features = test_instances[['nr_cities', 'nr_salesmen', 'average_distance', 'stddev_distance', 'density',\n",
    "                                'salesmen_ratio', 'bounding_box_area', 'aspect_ratio', 'spread',\n",
    "                                'cluster_compactness', 'mst_total_length', 'entropy_distance_matrix']]\n",
    "scaler = StandardScaler()\n",
    "test_features = scaler.fit_transform(test_features)\n",
    "\n",
    "x_test = torch.tensor(test_features, dtype=torch.float32)\n",
    "\n",
    "# model\n",
    "input_size = 12\n",
    "output_size = 4\n",
    "model = NeuralNetwork(input_size, output_size)\n",
    "model.load_state_dict(torch.load('models/best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "\n",
    "# mapping\n",
    "with open('labels_order.txt') as f:\n",
    "    label_order = [line.strip() for line in f]\n",
    "\n",
    "rename_dict = {\n",
    "    'Ant Colony': 'ant colony optimization',\n",
    "    'Branch and Cut': 'branch and cut',\n",
    "    'Greedy': 'greedy',\n",
    "    'KMeans-Greedy': 'kmeans greedy'\n",
    "}\n",
    "algorithm_mapping = {i: rename_dict[label] for i, label in enumerate(label_order)}\n",
    "\n",
    "predicted_algorithms = [algorithm_mapping[class_idx.item()] for class_idx in predicted_classes]\n",
    "test_instances['predicted_algorithm'] = predicted_algorithms\n",
    "\n",
    "# calculate composite score for each real algorithm\n",
    "test_algorithms = test_algorithms.merge(\n",
    "    test_instances[['instance_id', 'nr_cities']],\n",
    "    on='instance_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "test_algorithms['time_taken_norm'] = test_algorithms.groupby('instance_id')['time_taken'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    ")\n",
    "test_algorithms['distance_gap_norm'] = test_algorithms.groupby('instance_id')['distance_gap'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    ")\n",
    "\n",
    "is_small = test_algorithms['nr_cities'] <= 40\n",
    "is_bnc = test_algorithms['strategy'].str.lower().str.contains('branch and cut')\n",
    "\n",
    "test_algorithms['composite_score'] = (\n",
    "    test_algorithms['normalized_cost'] * np.where(is_small, 0.9, 0.6) +\n",
    "    test_algorithms['time_taken_norm'] * np.where(is_small & is_bnc, 0, np.where(is_small, 0.1, 0.2)) +\n",
    "    test_algorithms['distance_gap_norm'] * 0.05\n",
    ")\n",
    "\n",
    "#  best real algorithm for each instance\n",
    "best_real = test_algorithms.loc[test_algorithms.groupby('instance_id')['composite_score'].idxmin()]\n",
    "best_real = best_real[['instance_id', 'strategy']].rename(columns={'strategy': 'real_best_algorithm'})\n",
    "\n",
    "# compare predictions with real best algorithms\n",
    "comparison = test_instances[['instance_id', 'predicted_algorithm']].merge(best_real, on='instance_id')\n",
    "reverse_rename = {\n",
    "    'ant colony optimization': 'Ant Colony',\n",
    "    'branch and cut': 'Branch and Cut',\n",
    "    'greedy': 'Greedy',\n",
    "    'kmeans greedy': 'KMeans-Greedy'\n",
    "}\n",
    "\n",
    "comparison['predicted_algorithm_match'] = comparison['predicted_algorithm'].map(reverse_rename)\n",
    "comparison['match'] = (\n",
    "    comparison['predicted_algorithm_match'] == comparison['real_best_algorithm']\n",
    ")\n",
    "comparison.to_csv('comparatie_pred_vs_real.csv', index=False)\n",
    "\n",
    "accuracy = comparison['match'].mean()\n",
    "print(f\"Acuratetea retelei neruonale vechi: {accuracy:.2%}\")\n",
    "print(comparison.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f0b368f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea retelei neruonale vechi: 55.45%\n",
      "   instance_id predicted_algorithm real_best_algorithm  \\\n",
      "0            1      branch and cut      Branch and Cut   \n",
      "1            2      branch and cut      Branch and Cut   \n",
      "2            3      branch and cut      Branch and Cut   \n",
      "3            4      branch and cut      Branch and Cut   \n",
      "4            5      branch and cut      Branch and Cut   \n",
      "\n",
      "  predicted_algorithm_match  match  \n",
      "0            Branch and Cut   True  \n",
      "1            Branch and Cut   True  \n",
      "2            Branch and Cut   True  \n",
      "3            Branch and Cut   True  \n",
      "4            Branch and Cut   True  \n"
     ]
    }
   ],
   "source": [
    "# New Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.fc4 = nn.Linear(32, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "conn = sqlite3.connect('../test_mTSP.sqlite3')\n",
    "test_instances = pd.read_sql_query(\"SELECT * FROM instances\", conn)\n",
    "test_algorithms = pd.read_sql_query(\"SELECT * FROM algorithms\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "test_features = test_instances[['nr_cities', 'nr_salesmen', 'average_distance', 'stddev_distance', 'density',\n",
    "                                'salesmen_ratio', 'bounding_box_area', 'aspect_ratio', 'spread',\n",
    "                                'cluster_compactness', 'mst_total_length', 'entropy_distance_matrix']]\n",
    "scaler = StandardScaler()\n",
    "test_features = scaler.fit_transform(test_features)\n",
    "\n",
    "x_test = torch.tensor(test_features, dtype=torch.float32)\n",
    "\n",
    "# model\n",
    "input_size = 12\n",
    "output_size = 4\n",
    "model = NeuralNetwork(input_size, output_size)\n",
    "model.load_state_dict(torch.load('models_version2/best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "\n",
    "# mapping\n",
    "with open('labels_order.txt') as f:\n",
    "    label_order = [line.strip() for line in f]\n",
    "\n",
    "rename_dict = {\n",
    "    'Ant Colony': 'ant colony optimization',\n",
    "    'Branch and Cut': 'branch and cut',\n",
    "    'Greedy': 'greedy',\n",
    "    'KMeans-Greedy': 'kmeans greedy'\n",
    "}\n",
    "algorithm_mapping = {i: rename_dict[label] for i, label in enumerate(label_order)}\n",
    "\n",
    "predicted_algorithms = [algorithm_mapping[class_idx.item()] for class_idx in predicted_classes]\n",
    "test_instances['predicted_algorithm'] = predicted_algorithms\n",
    "\n",
    "# calculate composite score for each real algorithm\n",
    "test_algorithms = test_algorithms.merge(\n",
    "    test_instances[['instance_id', 'nr_cities']],\n",
    "    on='instance_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "test_algorithms['time_taken_norm'] = test_algorithms.groupby('instance_id')['time_taken'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    ")\n",
    "test_algorithms['distance_gap_norm'] = test_algorithms.groupby('instance_id')['distance_gap'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    ")\n",
    "\n",
    "is_small = test_algorithms['nr_cities'] <= 40\n",
    "is_bnc = test_algorithms['strategy'].str.lower().str.contains('branch and cut')\n",
    "\n",
    "test_algorithms['composite_score'] = (\n",
    "    test_algorithms['normalized_cost'] * np.where(is_small, 0.9, 0.6) +\n",
    "    test_algorithms['time_taken_norm'] * np.where(is_small & is_bnc, 0, np.where(is_small, 0.1, 0.2)) +\n",
    "    test_algorithms['distance_gap_norm'] * 0.05\n",
    ")\n",
    "\n",
    "#  best real algorithm for each instance\n",
    "best_real = test_algorithms.loc[test_algorithms.groupby('instance_id')['composite_score'].idxmin()]\n",
    "best_real = best_real[['instance_id', 'strategy']].rename(columns={'strategy': 'real_best_algorithm'})\n",
    "\n",
    "\n",
    "comparison = test_instances[['instance_id', 'predicted_algorithm']].merge(best_real, on='instance_id')\n",
    "reverse_rename = {\n",
    "    'ant colony optimization': 'Ant Colony',\n",
    "    'branch and cut': 'Branch and Cut',\n",
    "    'greedy': 'Greedy',\n",
    "    'kmeans greedy': 'KMeans-Greedy'\n",
    "}\n",
    "\n",
    "comparison['predicted_algorithm_match'] = comparison['predicted_algorithm'].map(reverse_rename)\n",
    "comparison['match'] = (\n",
    "    comparison['predicted_algorithm_match'] == comparison['real_best_algorithm']\n",
    ")\n",
    "\n",
    "comparison.to_csv('comparatie_pred_vs_real_version2.csv', index=False)\n",
    "\n",
    "accuracy = comparison['match'].mean()\n",
    "print(f\"Acuratetea retelei neruonale vechi: {accuracy:.2%}\")\n",
    "print(comparison.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
